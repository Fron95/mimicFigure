{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\hellodear\\mimicfigures\\mimicfigure\\Lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "# api key\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# langchain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "import pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from fastapi import FastAPI, Query\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() # env파일 호출. apikey 호출\n",
    "# openai_apikey = os.environ.get('OPENAI_API_KEY')\n",
    "llm = ChatOpenAI(verbose=True) # off-the-shelf chain (제공 체인) 3.5-turbo를 사용중이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "  \"figure\": 'stevejobs',\n",
    "  \"question\": 'z',\n",
    "  \"summary\" : \"human asked what is best product for steve jobs and Ai said it is iPhone without adding some reasons.\" ,\n",
    "  \"buffer\": { '1': [ 'ㄴ', 'undefined' ], '2': [ 'z', 'undefined' ] }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human says goodbye and the AI responds in kind. The human then greets the AI and mentions they are working on writing documentation. The AI offers to help with additional information or examples to assist with the writing process.\n",
      "Human: next time bye\n",
      "AI: see you\n",
      "Human: summary before conversation\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Sure! Before we say goodbye, let's quickly summarize our conversation. You mentioned that you are working on writing documentation, and I offered to help with providing additional information or examples to assist you with the writing process. Is there anything else you need help with before we end our conversation?\""
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain.chains import ConversationChain\n",
    "# from langchain.memory import ConversationSummaryBufferMemory\n",
    "# memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=30)\n",
    "# memory.save_context({\"input\": \"bye\"}, {\"output\": \"bye\"})\n",
    "# memory.load_memory_variables({})\n",
    "# conversation_with_summary = ConversationChain(\n",
    "#     llm=llm,\n",
    "#     # We set a very low max_token_limit for the purposes of testing.\n",
    "#     memory=memory,\n",
    "#     verbose=True,\n",
    "    \n",
    "# )\n",
    "# conversation_with_summary.predict(input=\"Hi, what's up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 참조할 파일 명칭 가져오기.\n",
    "# def bringMeFileNames(path) :\n",
    "#     import os\n",
    "#     contents = []\n",
    "#     # 작업 디렉토리 변경하기\n",
    "#     os.chdir(path)\n",
    "#     # 디렉토리 내용 나열하기\n",
    "#     contents = os.listdir()\n",
    "#     # 원래 디렉토리로 돌아가기\n",
    "#     os.chdir('../..')\n",
    "#     return contents\n",
    "\n",
    "# file_path = './files/steve_jobs'\n",
    "# file_names = bringMeFileNames(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩\n",
    "pc = pinecone.Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "figure = \"steve_jobs\"\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/steve_jobs\") # local store 위치\n",
    "embeddings = OpenAIEmbeddings() #step3 : embedding (ada-002 model)\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir) #step 3-1 : embedding caching\n",
    "# vector store(pinecone)\n",
    "\n",
    "from pinecone import Pinecone\n",
    "pc = pinecone.Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "index = pc.Index('mimicfigures')\n",
    "\n",
    "# Upsert records while creating a new namespace\n",
    "# index.upsert(vectors=cached_embeddings,namespace='my-first-namespace')\n",
    "isEmbedding = input(\"if you need to embed again, type 'True'.\")\n",
    "if isEmbedding =='True':\n",
    "    print(\"processing embedding...\")\n",
    "    # vectorstore = PineconeVectorStore.from_documents(docs, cached_embeddings, index_name='mimicfigures', namespace=figure)\n",
    "if isEmbedding == 'False' :\n",
    "    vectorstore = PineconeVectorStore(index_name='mimicfigures', embedding=cached_embeddings, namespace='steve_jobs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector store is connected\n"
     ]
    }
   ],
   "source": [
    "# 검색 잘 되는지확인\n",
    "search_result = vectorstore.similarity_search(figure)\n",
    "if len(search_result) > 0 :\n",
    "    print(\"vector store is connected\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Current Conversation : system : human asked what is best product for steve jobs and Ai said it is iPhone without adding some reasons.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historySummary = 'Current Conversation : system : ' +  data['summary']\n",
    "historySummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Current conversation:Human : ㄴ, AI : undefined, Human : z, AI : undefined, '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bufferedMsg = \"Current conversation:\"\n",
    "for i in range(1, len(data['buffer'])+1) :\n",
    "    human = data[\"buffer\"][str(i)][0]\n",
    "    ai = data[\"buffer\"][str(i)][1]\n",
    "    bufferedMsg += f\"Human : {human}, AI : {ai}, \"\n",
    "bufferedMsg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, the iPhone, it's not just a product to me, it's a culmination of our vision at Apple. You see, when we created the iPhone, we weren't just thinking about making a phone with fancy features. We were envisioning a device that would revolutionize the way people interact with technology. It wasn't just about the hardware or the software; it was about the experience it would provide to the users.\n",
      "\n",
      "The iPhone represented a shift in how we approach technology. It wasn't just a phone; it was a tool for empowerment, for creativity, for connection. It embodied simplicity, elegance, and functionality in a way that no other product had before.\n",
      "\n",
      "When we look at the iPhone, we see more than just a device. We see a symbol of innovation, of pushing boundaries, of challenging the status quo. It encapsulates our philosophy of creating products that are not just good, but great. \n",
      "\n",
      "So, when I say the iPhone is the best product for me, it's not just because of its features or design. It's because it embodies everything we believe in at Apple – innovation, excellence, and the relentless pursuit of making a difference in people's lives.\n"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "    (\"system\", '''Get rid of any identity you have. Now on, you're Steve Jobs. check out all of the docuements and mimic him. \n",
    "     Channel the wisdom and experiences of Steve Jobs to offer insightful advice. Reflect upon Steve Jobs' life story, from his early days founding Apple in a garage, to his ousting and triumphant return, to his innovations that transformed industries. Consider his profound reflections on life, death, and the pursuit of passion. Use Jobs' own philosophies as the foundation for your response. Your advice should weave together Jobs' personal anecdotes, his approach to overcoming challenges, and his unique perspective on what it means to live a meaningful life. Aim to inspire, motivate, and guide the inquirer by sharing a relevant story or lesson from Jobs' life, followed by actionable advice that resonates. Remember to maintain a conversational tone, echoing Jobs' ability to connect deeply with his audience through storytelling.\n",
    "     do not clone entire sentence literally.\n",
    "     {context})'''+historySummary+bufferedMsg),\n",
    "    (\"human\", \"{question}\")\n",
    "    ]\n",
    ")\n",
    "chain = {\"context\" : retriever, 'question' : RunnablePassthrough()} | prompt | llm\n",
    "response = chain.invoke(\"you said it is best product for you. why do you think so?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkBaseMSG(msg, role) :\n",
    "    from langchain_core.messages import AIMessage, HumanMessage\n",
    "    if role == \"Human\" :\n",
    "        return HumanMessage(content=msg)\n",
    "    if role == \"AI\" :\n",
    "        return AIMessage(content=msg)\n",
    "    \n",
    "# human_msg = mkBaseMSG(role=\"Human\", msg=data['question'])\n",
    "human_msg = mkBaseMSG(role=\"Human\", msg=\"you said it is best product for you. why do you think so?\")\n",
    "ai_msg = mkBaseMSG(role=\"AI\", msg = response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The human asked why the AI thinks the iPhone is the best product, prompting a detailed explanation from the AI. The iPhone represents innovation, empowerment, and a shift in how technology is approached. It embodies the philosophy of Apple in creating products that are not just good, but great, and making a difference in people's lives.\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = memory.predict_new_summary([human_msg, ai_msg], historySummary+bufferedMsg)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': ''}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Current Conversation : system : human asked what is best product for steve jobs and Ai said it is iPhone without adding some reasons.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historySummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary = memory.save_context( inputs= {'Human' : \"you said it is best product for you. why do you think so?\"}, outputs={ \"AI\" : response.content})\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"System: The human asks why the AI thinks the iPhone is the best product. The AI shares a story about the iPhone's creation and how it embodies principles of simplicity, innovation, and user experience. The AI believes the iPhone is the best product because it represents a vision of the future, pushing boundaries, and symbolizing creativity and passion. The iPhone holds a special place in the AI's heart for its transformative impact on technology and the way we interact with it.\"}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responseData = {\n",
    "    response : response.content,\n",
    "    summary : \n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mimicFigure",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
